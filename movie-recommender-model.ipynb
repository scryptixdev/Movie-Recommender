{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":792972,"sourceType":"datasetVersion","datasetId":1636}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 1 — Data Selection & Understanding  \n\nIn this first phase we:\n- Select a manageable subset of the Netflix Prize data.\n- Learn the structure of the files.\n- Stream large files in chunks (to fit into RAM).\n- Merge ratings with movie titles for readability.\n\nWe'll end up with a clean `DataFrame` of **UserID, MovieID, Rating, Title**.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\npd.set_option('display.max_columns', 50)\n\n# Path to your dataset (adjust as needed for Kaggle)\nDATA_DIR = Path(\"/kaggle/input/netflix-prize-data/\").resolve()\nCOMBINED_FILE = DATA_DIR / \"combined_data_1.txt\"\nMOVIE_TITLES = DATA_DIR / \"movie_titles.csv\"\n\nprint(\"Files exist?\", COMBINED_FILE.exists(), MOVIE_TITLES.exists())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:14:28.078172Z","iopub.execute_input":"2025-09-07T14:14:28.078478Z","iopub.status.idle":"2025-09-07T14:14:28.087679Z","shell.execute_reply.started":"2025-09-07T14:14:28.078452Z","shell.execute_reply":"2025-09-07T14:14:28.086447Z"}},"outputs":[{"name":"stdout","text":"Files exist? True True\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def stream_combined_ratings(path: Path, max_rows: int = None) -> pd.DataFrame:\n    \"\"\"\n    Stream-read combined_data file.\n    Returns DataFrame with UserID, MovieID, Rating, Date.\n    max_rows lets you limit rows for memory reasons.\n    \"\"\"\n    rows = []\n    current_movie = None\n    count = 0\n    with open(path, 'r', encoding='latin-1') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            if line.endswith(':'):  # new movie block\n                current_movie = int(line[:-1])\n                continue\n            user_id, rating, date = line.split(',')\n            rows.append((int(user_id), current_movie, float(rating), date))\n            count += 1\n            if max_rows is not None and count >= max_rows:\n                break\n    return pd.DataFrame(rows, columns=['UserID','MovieID','Rating','Date'])\n\n# Example: read first 500k rows (adjust based on RAM)\nratings_df = stream_combined_ratings(COMBINED_FILE, max_rows=500_000)\nratings_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:14:38.557788Z","iopub.execute_input":"2025-09-07T14:14:38.558085Z","iopub.status.idle":"2025-09-07T14:14:39.085237Z","shell.execute_reply.started":"2025-09-07T14:14:38.558061Z","shell.execute_reply":"2025-09-07T14:14:39.084563Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    UserID  MovieID  Rating        Date\n0  1488844        1     3.0  2005-09-06\n1   822109        1     5.0  2005-05-13\n2   885013        1     4.0  2005-10-19\n3    30878        1     4.0  2005-12-26\n4   823519        1     3.0  2004-05-03","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>MovieID</th>\n      <th>Rating</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1488844</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2005-09-06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>822109</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>2005-05-13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>885013</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2005-10-19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30878</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2005-12-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>823519</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2004-05-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"rows = []\nwith open(MOVIE_TITLES, 'r', encoding='latin-1') as f:\n    for line in f:\n        # split only first two commas, rest stays in title\n        parts = line.strip().split(',', 2)\n        if len(parts) < 3:\n            continue\n        movie_id = int(parts[0])\n        year = int(parts[1]) if parts[1].isdigit() else None\n        title = parts[2]\n        rows.append((movie_id, year, title))\n\ntitles_df = pd.DataFrame(rows, columns=['MovieID','Year','Title'])\ntitles_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:15:41.782195Z","iopub.execute_input":"2025-09-07T14:15:41.782451Z","iopub.status.idle":"2025-09-07T14:15:41.817362Z","shell.execute_reply.started":"2025-09-07T14:15:41.782429Z","shell.execute_reply":"2025-09-07T14:15:41.816381Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   MovieID    Year                         Title\n0        1  2003.0               Dinosaur Planet\n1        2  2004.0    Isle of Man TT 2004 Review\n2        3  1997.0                     Character\n3        4  1994.0  Paula Abdul's Get Up & Dance\n4        5  2004.0      The Rise and Fall of ECW","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MovieID</th>\n      <th>Year</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2003.0</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2004.0</td>\n      <td>Isle of Man TT 2004 Review</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1997.0</td>\n      <td>Character</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1994.0</td>\n      <td>Paula Abdul's Get Up &amp; Dance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2004.0</td>\n      <td>The Rise and Fall of ECW</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"ratings_df = ratings_df.merge(\n    titles_df[['MovieID','Title']], on='MovieID', how='left'\n)\nratings_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:15:53.037087Z","iopub.execute_input":"2025-09-07T14:15:53.037352Z","iopub.status.idle":"2025-09-07T14:15:53.082091Z","shell.execute_reply.started":"2025-09-07T14:15:53.037330Z","shell.execute_reply":"2025-09-07T14:15:53.080843Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"    UserID  MovieID  Rating        Date            Title\n0  1488844        1     3.0  2005-09-06  Dinosaur Planet\n1   822109        1     5.0  2005-05-13  Dinosaur Planet\n2   885013        1     4.0  2005-10-19  Dinosaur Planet\n3    30878        1     4.0  2005-12-26  Dinosaur Planet\n4   823519        1     3.0  2004-05-03  Dinosaur Planet","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>MovieID</th>\n      <th>Rating</th>\n      <th>Date</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1488844</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2005-09-06</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>822109</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>2005-05-13</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>885013</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2005-10-19</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30878</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2005-12-26</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>823519</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2004-05-03</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Phase 2 — Pre-processing  \n\nWe’ll clean and type-convert our data to make it ready for modelling:\n- Convert IDs to integers.\n- Convert Rating to float.\n- Parse Date to datetime.\n- Drop obvious missing values if any.\n- Split into train/test per user (80/20) to simulate a recommendation scenario.\n","metadata":{}},{"cell_type":"code","source":"# Ensure correct types\nratings_df['UserID'] = ratings_df['UserID'].astype('int32')\nratings_df['MovieID'] = ratings_df['MovieID'].astype('int32')\nratings_df['Rating'] = ratings_df['Rating'].astype('float32')\n\n# Convert date to datetime\nratings_df['Date'] = pd.to_datetime(ratings_df['Date'], errors='coerce')\n\n# Drop rows with missing values (should be minimal)\nratings_df = ratings_df.dropna(subset=['UserID','MovieID','Rating'])\n\nratings_df.info()\nratings_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:17:09.149557Z","iopub.execute_input":"2025-09-07T14:17:09.149892Z","iopub.status.idle":"2025-09-07T14:17:09.273061Z","shell.execute_reply.started":"2025-09-07T14:17:09.149871Z","shell.execute_reply":"2025-09-07T14:17:09.271998Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500000 entries, 0 to 499999\nData columns (total 5 columns):\n #   Column   Non-Null Count   Dtype         \n---  ------   --------------   -----         \n 0   UserID   500000 non-null  int32         \n 1   MovieID  500000 non-null  int32         \n 2   Rating   500000 non-null  float32       \n 3   Date     500000 non-null  datetime64[ns]\n 4   Title    500000 non-null  object        \ndtypes: datetime64[ns](1), float32(1), int32(2), object(1)\nmemory usage: 13.4+ MB\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"    UserID  MovieID  Rating       Date            Title\n0  1488844        1     3.0 2005-09-06  Dinosaur Planet\n1   822109        1     5.0 2005-05-13  Dinosaur Planet\n2   885013        1     4.0 2005-10-19  Dinosaur Planet\n3    30878        1     4.0 2005-12-26  Dinosaur Planet\n4   823519        1     3.0 2004-05-03  Dinosaur Planet","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>MovieID</th>\n      <th>Rating</th>\n      <th>Date</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1488844</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2005-09-06</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>822109</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>2005-05-13</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>885013</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2005-10-19</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30878</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2005-12-26</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>823519</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2004-05-03</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef split_train_test_per_user(df, test_size=0.2, seed=42):\n    np.random.seed(seed)\n    train_parts = []\n    test_parts = []\n    for user_id, user_df in tqdm(df.groupby('UserID'), desc=\"Splitting users\"):\n        # random permute indices for this user\n        idx = np.arange(len(user_df))\n        np.random.shuffle(idx)\n        cutoff = int(len(idx) * (1 - test_size))\n        train_idx = idx[:cutoff]\n        test_idx = idx[cutoff:]\n        train_parts.append(user_df.iloc[train_idx])\n        test_parts.append(user_df.iloc[test_idx])\n    train_df = pd.concat(train_parts).reset_index(drop=True)\n    test_df = pd.concat(test_parts).reset_index(drop=True)\n    return train_df, test_df\n\ntrain_df, test_df = split_train_test_per_user(ratings_df, test_size=0.2)\n\nprint(\"Train size:\", len(train_df), \"Test size:\", len(test_df))\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:18:00.184845Z","iopub.execute_input":"2025-09-07T14:18:00.185114Z","iopub.status.idle":"2025-09-07T14:20:30.876207Z","shell.execute_reply.started":"2025-09-07T14:18:00.185091Z","shell.execute_reply":"2025-09-07T14:20:30.874178Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Splitting users:   0%|          | 0/215008 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a994155c846c4cf0a11947bdc4e726fa"}},"metadata":{}},{"name":"stdout","text":"Train size: 266701 Test size: 233299\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   UserID  MovieID  Rating       Date                       Title\n0       7       28     4.0 2005-05-23             Lilo and Stitch\n1       7       83     5.0 2005-10-30                    Silkwood\n2       7        8     5.0 2005-07-30  What the #$*! Do We Know!?\n3      79       84     3.0 2004-07-06   The Powerpuff Girls Movie\n4      87       95     1.0 2005-05-19   Dona Herlinda and Her Son","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>MovieID</th>\n      <th>Rating</th>\n      <th>Date</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>28</td>\n      <td>4.0</td>\n      <td>2005-05-23</td>\n      <td>Lilo and Stitch</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>83</td>\n      <td>5.0</td>\n      <td>2005-10-30</td>\n      <td>Silkwood</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>8</td>\n      <td>5.0</td>\n      <td>2005-07-30</td>\n      <td>What the #$*! Do We Know!?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>79</td>\n      <td>84</td>\n      <td>3.0</td>\n      <td>2004-07-06</td>\n      <td>The Powerpuff Girls Movie</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>87</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>2005-05-19</td>\n      <td>Dona Herlinda and Her Son</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# Phase 3 — Baseline Models  \n\nWe start with simple baselines to understand the recommendation concept.\n\n## 1. Popularity-based Recommendation  \nRecommend the movies that are most popular (highest average rating or most ratings overall).  \nNo personalization yet.\n\n## 2. User-based Collaborative Filtering (CF)  \nFind users who rated things similarly (cosine similarity) and recommend what they liked.  \n\nThese baselines give us a sense of how well “trivial” models perform before we try more advanced methods.\n","metadata":{}},{"cell_type":"code","source":"# Compute average rating and count per movie from the training set\nmovie_stats = (\n    train_df.groupby(['MovieID','Title'])['Rating']\n    .agg(['mean','count'])\n    .reset_index()\n    .rename(columns={'mean':'AvgRating','count':'NumRatings'})\n)\n\n# Top-N by number of ratings (or by avg rating if you prefer)\ntop_movies = movie_stats.sort_values('NumRatings', ascending=False).head(20)\ntop_movies[['Title','NumRatings','AvgRating']].head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:23:08.349675Z","iopub.execute_input":"2025-09-07T14:23:08.350289Z","iopub.status.idle":"2025-09-07T14:23:08.404620Z","shell.execute_reply.started":"2025-09-07T14:23:08.350241Z","shell.execute_reply":"2025-09-07T14:23:08.403346Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                          Title  NumRatings  AvgRating\n29       Something's Gotta Give       46142   3.723159\n142                    The Game       22541   3.823122\n27              Lilo and Stitch       21337   3.796035\n110         Duplex (Widescreen)       16802   3.082907\n117  Rambo: First Blood Part II       11857   3.410137\n82                     Silkwood       11319   3.706246\n57                  Dragonheart       11156   3.592954\n107                     Spartan       11009   3.180034\n76                        Congo        8644   2.843359\n7    What the #$*! Do We Know!?        6888   3.149100","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>NumRatings</th>\n      <th>AvgRating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <td>Something's Gotta Give</td>\n      <td>46142</td>\n      <td>3.723159</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>The Game</td>\n      <td>22541</td>\n      <td>3.823122</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Lilo and Stitch</td>\n      <td>21337</td>\n      <td>3.796035</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>Duplex (Widescreen)</td>\n      <td>16802</td>\n      <td>3.082907</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>Rambo: First Blood Part II</td>\n      <td>11857</td>\n      <td>3.410137</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Silkwood</td>\n      <td>11319</td>\n      <td>3.706246</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Dragonheart</td>\n      <td>11156</td>\n      <td>3.592954</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>Spartan</td>\n      <td>11009</td>\n      <td>3.180034</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Congo</td>\n      <td>8644</td>\n      <td>2.843359</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>What the #$*! Do We Know!?</td>\n      <td>6888</td>\n      <td>3.149100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def recommend_popular(n=10):\n    return top_movies.head(n)[['Title','NumRatings','AvgRating']]\n\nrecommend_popular(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:23:22.042013Z","iopub.execute_input":"2025-09-07T14:23:22.042311Z","iopub.status.idle":"2025-09-07T14:23:22.056731Z","shell.execute_reply.started":"2025-09-07T14:23:22.042288Z","shell.execute_reply":"2025-09-07T14:23:22.054559Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                          Title  NumRatings  AvgRating\n29       Something's Gotta Give       46142   3.723159\n142                    The Game       22541   3.823122\n27              Lilo and Stitch       21337   3.796035\n110         Duplex (Widescreen)       16802   3.082907\n117  Rambo: First Blood Part II       11857   3.410137\n82                     Silkwood       11319   3.706246\n57                  Dragonheart       11156   3.592954\n107                     Spartan       11009   3.180034\n76                        Congo        8644   2.843359\n7    What the #$*! Do We Know!?        6888   3.149100","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>NumRatings</th>\n      <th>AvgRating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <td>Something's Gotta Give</td>\n      <td>46142</td>\n      <td>3.723159</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>The Game</td>\n      <td>22541</td>\n      <td>3.823122</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Lilo and Stitch</td>\n      <td>21337</td>\n      <td>3.796035</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>Duplex (Widescreen)</td>\n      <td>16802</td>\n      <td>3.082907</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>Rambo: First Blood Part II</td>\n      <td>11857</td>\n      <td>3.410137</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Silkwood</td>\n      <td>11319</td>\n      <td>3.706246</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Dragonheart</td>\n      <td>11156</td>\n      <td>3.592954</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>Spartan</td>\n      <td>11009</td>\n      <td>3.180034</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Congo</td>\n      <td>8644</td>\n      <td>2.843359</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>What the #$*! Do We Know!?</td>\n      <td>6888</td>\n      <td>3.149100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\n# Build a small user-item matrix for demo (e.g., first 5,000 users)\nsample_users = train_df['UserID'].drop_duplicates().sample(5000, random_state=42)\nuser_item = (\n    train_df[train_df['UserID'].isin(sample_users)]\n    .pivot_table(index='UserID', columns='MovieID', values='Rating')\n    .fillna(0)\n)\n\n# Compute cosine similarity between users\nuser_sim = cosine_similarity(user_item)\nuser_sim_df = pd.DataFrame(user_sim, index=user_item.index, columns=user_item.index)\n\ndef recommend_user_based(user_id, top_n=10):\n    if user_id not in user_sim_df.index:\n        return recommend_popular(top_n)  # fallback\n    # get most similar users (excluding self)\n    similar_users = user_sim_df.loc[user_id].drop(user_id).sort_values(ascending=False).index[:10]\n    # gather movies those similar users rated highly\n    similar_ratings = train_df[train_df['UserID'].isin(similar_users)]\n    # exclude movies the target user has already rated\n    seen_movies = set(train_df.loc[train_df['UserID']==user_id, 'MovieID'])\n    # compute average rating per movie among similar users\n    recs = (\n        similar_ratings[~similar_ratings['MovieID'].isin(seen_movies)]\n        .groupby(['MovieID','Title'])['Rating'].mean()\n        .reset_index()\n        .sort_values('Rating', ascending=False)\n        .head(top_n)\n    )\n    return recs[['Title','Rating']]\n\n# Example usage:\nsample_user = user_item.index[0]\nrecommend_user_based(sample_user, top_n=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:23:47.946936Z","iopub.execute_input":"2025-09-07T14:23:47.947248Z","iopub.status.idle":"2025-09-07T14:23:48.856357Z","shell.execute_reply.started":"2025-09-07T14:23:47.947224Z","shell.execute_reply":"2025-09-07T14:23:48.855460Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Title, Rating]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"# Phase 4 — Matrix Factorization (SVD)\n\nMatrix Factorization captures hidden (latent) factors for users and movies.\n\n- Each user and each movie is represented by a vector of *k* latent factors.\n- The dot product of these vectors gives the predicted rating.\n\nWe’ll use the [`surprise`](https://surprise.readthedocs.io/) library’s **SVD** implementation to train a simple model and compare it to our baselines.\n","metadata":{}},{"cell_type":"code","source":"# Install scikit-surprise if not already installed\n# (In Kaggle you may need to uncomment)\n# !pip install scikit-surprise\n\nfrom surprise import SVD, Dataset, Reader\nfrom surprise.model_selection import train_test_split as surprise_split\nfrom surprise.model_selection import cross_validate\nfrom surprise import accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:25:11.838522Z","iopub.execute_input":"2025-09-07T14:25:11.839008Z","iopub.status.idle":"2025-09-07T14:25:11.930164Z","shell.execute_reply.started":"2025-09-07T14:25:11.838981Z","shell.execute_reply":"2025-09-07T14:25:11.929114Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Surprise expects a dataframe with at least user, item, rating columns.\n# We'll use our train_df/test_df prepared earlier.\n\nreader = Reader(rating_scale=(1, 5))  # Netflix ratings 1–5\ndata = Dataset.load_from_df(train_df[['UserID', 'MovieID', 'Rating']], reader)\n\n# Surprise has its own train/test split, but we can also build a Trainset from ours:\ntrainset = data.build_full_trainset()\n\n# Build testset from our test_df\ntestset = list(test_df[['UserID','MovieID','Rating']].itertuples(index=False, name=None))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:25:21.428774Z","iopub.execute_input":"2025-09-07T14:25:21.429230Z","iopub.status.idle":"2025-09-07T14:25:21.749152Z","shell.execute_reply.started":"2025-09-07T14:25:21.429207Z","shell.execute_reply":"2025-09-07T14:25:21.748357Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Train SVD\nalgo = SVD(n_factors=50, reg_all=0.02, lr_all=0.005, n_epochs=20)\nalgo.fit(trainset)\n\n# Predict on testset\npredictions = algo.test(testset)\n\n# Evaluate RMSE\nrmse = accuracy.rmse(predictions)\nprint(\"Test RMSE:\", rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:25:30.618266Z","iopub.execute_input":"2025-09-07T14:25:30.618554Z","iopub.status.idle":"2025-09-07T14:25:32.807334Z","shell.execute_reply.started":"2025-09-07T14:25:30.618534Z","shell.execute_reply":"2025-09-07T14:25:32.805895Z"}},"outputs":[{"name":"stdout","text":"RMSE: 1.0000\nTest RMSE: 1.0000445726603848\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def recommend_svd(user_id, n=10):\n    \"\"\"Recommend n movies to user_id using trained SVD model.\"\"\"\n    # Get all movie IDs\n    all_movie_ids = train_df['MovieID'].unique()\n    # Movies user has already rated\n    seen_movies = set(train_df.loc[train_df['UserID']==user_id, 'MovieID'])\n    # Predict rating for all unseen movies\n    preds = []\n    for mid in all_movie_ids:\n        if mid not in seen_movies:\n            preds.append((mid, algo.predict(user_id, mid).est))\n    # Sort by predicted rating\n    top_n = sorted(preds, key=lambda x: x[1], reverse=True)[:n]\n    # Attach titles\n    recs = titles_df[titles_df['MovieID'].isin([m for m,_ in top_n])][['MovieID','Title']]\n    scores = pd.DataFrame(top_n, columns=['MovieID','PredRating'])\n    return recs.merge(scores, on='MovieID').sort_values('PredRating', ascending=False)\n\n# Example usage:\nuser_example = train_df['UserID'].iloc[0]\nrecommend_svd(user_example, n=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:25:44.338545Z","iopub.execute_input":"2025-09-07T14:25:44.338839Z","iopub.status.idle":"2025-09-07T14:25:44.366721Z","shell.execute_reply.started":"2025-09-07T14:25:44.338820Z","shell.execute_reply":"2025-09-07T14:25:44.364585Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   MovieID                                              Title  PredRating\n0       13  Lord of the Rings: The Return of the King: Ext...    4.826930\n3       33                     Aqua Teen Hunger Force: Vol. 1    4.726719\n9      106  Stevie Ray Vaughan and Double Trouble: Live at...    4.549478\n2       32  ABC Primetime: Mel Gibson's The Passion of the...    4.456822\n7       97                                      Mostly Martha    4.407733\n6       85                                         Elfen Lied    4.395100\n8       98              The Battle of Algiers: Bonus Material    4.372178\n5       76                              I Love Lucy: Season 2    4.352892\n1       25      Inspector Morse 31: Death Is Now My Neighbour    4.312666\n4       37                              Zatoichi's Conspiracy    4.297958","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MovieID</th>\n      <th>Title</th>\n      <th>PredRating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>Lord of the Rings: The Return of the King: Ext...</td>\n      <td>4.826930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>Aqua Teen Hunger Force: Vol. 1</td>\n      <td>4.726719</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>106</td>\n      <td>Stevie Ray Vaughan and Double Trouble: Live at...</td>\n      <td>4.549478</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>ABC Primetime: Mel Gibson's The Passion of the...</td>\n      <td>4.456822</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>97</td>\n      <td>Mostly Martha</td>\n      <td>4.407733</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>85</td>\n      <td>Elfen Lied</td>\n      <td>4.395100</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>98</td>\n      <td>The Battle of Algiers: Bonus Material</td>\n      <td>4.372178</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>76</td>\n      <td>I Love Lucy: Season 2</td>\n      <td>4.352892</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>Inspector Morse 31: Death Is Now My Neighbour</td>\n      <td>4.312666</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>Zatoichi's Conspiracy</td>\n      <td>4.297958</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"# Phase 5 — Evaluation & Metrics\n\nWe already computed **RMSE** for rating prediction.\nNow we’ll add ranking metrics:\n\n- **Precision@k:** Of the top-k recommendations, what fraction are actually relevant?\n- **Recall@k:** Of all the relevant items for the user, how many did we recommend in the top-k?\n\nThis shows how well our model does at recommending good movies rather than just predicting ratings.\n","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\n\ndef get_top_n(predictions, n=10):\n    \"\"\"Return the top-N recommendation for each user from a list of Surprise predictions.\"\"\"\n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n    # sort each user's predictions and keep top n\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n    return top_n\n\n# Build top-N recommendations for all users\ntop_n_preds = get_top_n(predictions, n=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:26:30.695122Z","iopub.execute_input":"2025-09-07T14:26:30.695424Z","iopub.status.idle":"2025-09-07T14:26:30.908215Z","shell.execute_reply.started":"2025-09-07T14:26:30.695400Z","shell.execute_reply":"2025-09-07T14:26:30.907250Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def precision_recall_at_k(predictions, k=10, threshold=4.0):\n    \"\"\"Return precision@k and recall@k for each user.\"\"\"\n    # map user to list of predictions sorted by est descending\n    user_est_true = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        user_est_true[uid].append((est, true_r))\n    \n    precisions = dict()\n    recalls = dict()\n    \n    for uid, user_ratings in user_est_true.items():\n        # sort by estimated rating\n        user_ratings.sort(key=lambda x: x[0], reverse=True)\n        # number of relevant items in top k\n        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n        n_rec_k = sum((true_r >= threshold) for (_, true_r) in user_ratings[:k])\n        n_rel_k = sum((true_r >= threshold) for (_, true_r) in user_ratings[:k])\n        \n        precisions[uid] = n_rec_k / k if k != 0 else 1\n        recalls[uid] = n_rel_k / n_rel if n_rel != 0 else 1\n    \n    return precisions, recalls\n\nprecisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4.0)\n\nprint(\"Mean Precision@10:\", np.mean(list(precisions.values())))\nprint(\"Mean Recall@10:\", np.mean(list(recalls.values())))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:26:43.767482Z","iopub.execute_input":"2025-09-07T14:26:43.767784Z","iopub.status.idle":"2025-09-07T14:26:44.243970Z","shell.execute_reply.started":"2025-09-07T14:26:43.767761Z","shell.execute_reply":"2025-09-07T14:26:44.242932Z"}},"outputs":[{"name":"stdout","text":"Mean Precision@10: 0.06254930049114453\nMean Recall@10: 0.999990720819508\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# You can peek at similar movies by looking at item factors (algo.qi)\n# For demonstration: compute cosine similarity between movie latent factors\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nmovie_factors = algo.qi  # latent factors for each movie (ordered by inner id)\nsimilarities = cosine_similarity(movie_factors)\n\n# Map back to MovieIDs:\ninner_to_raw = {inner: algo.trainset.to_raw_iid(inner) for inner in range(algo.trainset.n_items)}\n\ndef similar_movies(movie_id, top_n=10):\n    \"\"\"Find top_n most similar movies (by latent factors) to a given movie_id.\"\"\"\n    inner_id = algo.trainset.to_inner_iid(movie_id)\n    sim_scores = list(enumerate(similarities[inner_id]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    # skip the first one (itself)\n    sim_scores = sim_scores[1:top_n+1]\n    sim_movie_ids = [int(inner_to_raw[idx]) for idx, _ in sim_scores]\n    return titles_df[titles_df['MovieID'].isin(sim_movie_ids)][['MovieID','Title']]\n\n# Example: find movies similar to a specific MovieID\nexample_movie_id = train_df['MovieID'].iloc[0]\nsimilar_movies(example_movie_id, top_n=5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:27:01.295445Z","iopub.execute_input":"2025-09-07T14:27:01.295785Z","iopub.status.idle":"2025-09-07T14:27:01.322424Z","shell.execute_reply.started":"2025-09-07T14:27:01.295762Z","shell.execute_reply":"2025-09-07T14:27:01.321075Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"     MovieID                              Title\n17        18                   Immortal Beloved\n83        84          The Powerpuff Girls Movie\n117      118         Rambo: First Blood Part II\n118      119  Travel the World by Train: Africa\n121      122                  Cube 2: Hypercube","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MovieID</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>Immortal Beloved</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>84</td>\n      <td>The Powerpuff Girls Movie</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>118</td>\n      <td>Rambo: First Blood Part II</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>119</td>\n      <td>Travel the World by Train: Africa</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>122</td>\n      <td>Cube 2: Hypercube</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25}]}